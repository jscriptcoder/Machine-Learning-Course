# Week 3

## Logistic Regression ##

Welcome to week 3! This week, we’ll be covering logistic regression. Logistic regression is a method for classifying data into discrete outcomes. For example, we might use logistic regression to classify an email as spam or not spam. In this module, we introduce the notion of classification, the cost function for logistic regression, and the application of logistic regression to multi-class classification.

We are also covering regularization. Machine learning models need to generalize well to new examples that the model has not seen in practice. We’ll introduce regularization, which helps prevent models from overfitting the training data.

As always, if you get stuck on the quiz and programming assignment, you should post on the Discussions to ask for help. (And if you finish early, I hope you'll go there to help your fellow classmates as well.)

### Classification and Representation ###

- [x] Classification
- [x] Hypothesis Representation
- [x] Decision Boundary

### Logistic Regression Model ###

- [x] Cost Function
- [x] Simplified Cost Function and Gradient Descent
- [x] Advanced Optimization

### Multiclass Classification ###
- [x] Multiclass Classification: One-vs-all

**Review**
- [Lecture Slides](lecture6.pdf)

**Quiz**
- [x] Logistic Regression

## Regularization ##

Machine learning models need to generalize well to new examples that the model has not seen in practice. In this module, we introduce regularization, which helps prevent models from overfitting the training data.

### Solving the Problem of Overfitting ###

- [x] The Problem of Overfitting
- [x] Cost Function
- [x] Regularized Linear Regression
- [x] Regularized Logistic Regression

**Review**
- [Lecture Slides](lecture7.pdf)

**Quiz**
- [x] Regularization

**Programming Assignment**
- [x] Logistic Regression
